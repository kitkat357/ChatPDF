{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kitkat357/ChatPDF/blob/main/KWK_Titanic_Survival_Data_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KWK Machine Learning Challenge 2025\n",
        "##Titanic Survival Data Notebook\n",
        "\n",
        "Make a copy of this notebook and follow along with the guided curriculum lessons!\n",
        "\n",
        "Portions of code for you to complete are marked with a #TODO comment."
      ],
      "metadata": {
        "id": "y14YBNqzg35a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting files from Google Colab"
      ],
      "metadata": {
        "id": "lIclQZ12hIjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For more information on this, see this link: https://colab.research.google.com/notebooks/io.ipynb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4YmdXOiThHd",
        "outputId": "50a46c8a-5341-4bf1-c9e7-bd9a7dc82ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zGfwLT0g8_n"
      },
      "outputs": [],
      "source": [
        "# Basic import statements\n",
        "import pandas as pd\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data into a Dataframe\n",
        "First, we load the data from the CSV file into a pandas dataframe. Read more about pandas dataframes [here](https://pandas.pydata.org/docs/user_guide/dsintro.html).\n",
        "\n",
        "After we load the data using the `read_csv` function, we preview the dataframe using `df.head()` and visually inspect the results to ensure it was loaded as we expected."
      ],
      "metadata": {
        "id": "fvOS2xDl4-V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Replace the path below with the path to the file on your own Google Drive.\n",
        "df = pd.read_csv(\"path\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "Asx9iDoC4r2_",
        "outputId": "1ebb296b-4282-430b-8d35-d71d421fd73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1895073965.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Replace the path below with the path to the file on your own Google Drive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This should have some output if your dataframe was loaded correctly.\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "hGsmLozp1W1H",
        "outputId": "cc528476-1640-46a6-e8f5-eacbd340a5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1346493725.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#This should have some output if your dataframe was loaded correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STAT1.1.1 - Data Types\n",
        "\n",
        "Below is a list of the columns in the Titanic dataset.\n",
        "Record what kind of data each represents.\n",
        "Use the following categories to classify each variable:\n",
        "\n",
        "* Continuous quantitative data\n",
        "* Discrete quantitative data\n",
        "* Nominal qualitative data\n",
        "* Ordinal qualitative data\n",
        "* Other common types (select which)\n",
        "\n",
        "| Column Name   | Description                          | Data Type                      | Explanation                                                                          |\n",
        "| ------------- | ------------------------------------ | ------------------------------ | ------------------------------------------------------------------------------------ |\n",
        "| `PassengerId` | Unique identifier for each passenger | **TODO - Answer** | TODO - Explain |\n",
        "| `Survived`    | Survival status (0 = No, 1 = Yes)    | **TODO - Answer** | TODO - Explain |\n",
        "| `Pclass`      | Ticket class (1st, 2nd, 3rd)         | **TODO - Answer** | TODO - Explain |\n",
        "| `Name`        | Passengerâ€™s full name                |  **TODO - Answer** | TODO - Explain |\n",
        "| `Sex`         | Gender of passenger                  | **TODO - Answer** | TODO - Explain |\n",
        "| `Age`         | Age in years                         |  **TODO - Answer** | TODO - Explain |\n",
        "| `SibSp`       | Number of siblings/spouses aboard    |  **TODO - Answer** | TODO - Explain |                                                          \n",
        "| `Parch`       | Number of parents/children aboard    |  **TODO - Answer** | TODO - Explain |\n",
        "| `Ticket`      | Ticket number                        | **TODO - Answer** | TODO - Explain |\n",
        "| `Fare`        | Ticket price                         | **TODO - Answer** | TODO - Explain |\n",
        "| `Cabin`       | Cabin number                         | **TODO - Answer** | TODO - Explain |\n",
        "| `Embarked`    | Port of embarkation (C, Q, S)        |  **TODO - Answer** | TODO - Explain |\n"
      ],
      "metadata": {
        "id": "-_Amrcms1GlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STAT1.1.2 - Calculating Measures of Central Tendency\n",
        "Let's start by finding the measures of central tendency of each numeric variable in the Titanic dataset.\n",
        "\n",
        "By calculating the mean, median, and mode for columns like `Age`, `SibSp`, `Parch`, `Fare`, and `Pclass`, we can get a sense of what was typical for passengers on board: their average age, common ticket class, and usual family size.\n",
        "These measures help summarize large amounts of data into a few meaningful numbers that tell the story of who was on the ship."
      ],
      "metadata": {
        "id": "t_BXlaDY448g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select numeric columns to analyze\n",
        "# Weâ€™ll focus on three continuous or discrete quantitative variables\n",
        "cols = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\"]\n",
        "\n",
        "# Loop through each column and compute measures of spread\n",
        "for col in cols:\n",
        "    print(f\"\\n--- {col.upper()} ---\")\n",
        "\n",
        "    # Calculate Mean\n",
        "    #TODO:  calculate the mean age and assign to the variable `mean_age`\n",
        "    print(f\"Mean: {mean_age}\")\n",
        "\n",
        "    # Calculate Median\n",
        "    #TODO:  calculate the median age and assign to the variable `median_age`\n",
        "    print(f\"Median: {median_age}\")\n",
        "\n",
        "    # Calculate Mode\n",
        "    # This example is a bit more complicated, so it's done for you below\n",
        "    mode_result = stats.mode(df[col], keepdims=True)\n",
        "    mode_age = mode_result.mode[0]\n",
        "    count_mode = mode_result.count[0]\n",
        "    print(f\"Mode: {mode_age} (appears {count_mode} times)\")"
      ],
      "metadata": {
        "id": "pCspE4sm5ynt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ’­ Reflection: Interpreting Correlations\n",
        "\n",
        "**What do these averages tell us about who was on board the Titanic?**\n",
        "\n",
        "TODO - answer\n",
        "\n",
        "**What do the results for SibSp and Parch suggest about how people traveled?**\n",
        "\n",
        "TODO - answer"
      ],
      "metadata": {
        "id": "W7HE2B90wjGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STAT1.1.3 - Calculating Spread and Variation\n",
        "\n",
        "Now that we know what was typical for passengers aboard the Titanic, let's look at how much variation there was between them.\n",
        "\n",
        "By calculating the **range**, **interquartile range** (IQR), and **standard deviation** for features like `Age`, `Fare`, and `Pclass`, we can see how widely passengers differed in age, ticket price, and social class."
      ],
      "metadata": {
        "id": "BukmRwogYGdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select numeric columns to analyze\n",
        "# Weâ€™ll focus on three continuous or discrete quantitative variables\n",
        "cols = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\"]\n",
        "\n",
        "# Loop through each column and compute measures of spread\n",
        "for col in cols:\n",
        "    print(f\"\\n--- {col.upper()} ---\")\n",
        "\n",
        "    # TODO - calculate and print min, max, range, IQR, and standard deviation for each column"
      ],
      "metadata": {
        "id": "WC-ugxHQcqXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we understand how measures like range, IQR, and standard deviation describe variation, let's see what that spread looks like visually. Box plots are a simple way to compare how much values differ within and across variables."
      ],
      "metadata": {
        "id": "LbYHX5wie467"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define numeric columns to visualize\n",
        "cols = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Pclass\"]\n",
        "\n",
        "#TODO - create a box plot for each feature\n"
      ],
      "metadata": {
        "id": "zcTjKxR8eOtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A box plot shows how data is distributed at a glance. The box itself represents the middle 50% of the data (from the 25th percentile (Q1) to the 75th percentile (Q3)) with the line inside marking the median. The \"whiskers\" extend to show the overall range of typical values, and any points beyond them are outliers. A taller box means more variability, while a shorter one means the data is more consistent."
      ],
      "metadata": {
        "id": "CqVzrDQxfTMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’­ Reflection: Variation and Spread\n",
        "\n",
        "**Which variable shows the most variation, and what does that tell us about conditions aboard the Titanic?**\n",
        "\n",
        "TODO - answer\n",
        "\n",
        "**Which variables show the least variation, and what might that suggest about passenger demographics?**\n",
        "\n",
        "TODO - answer"
      ],
      "metadata": {
        "id": "xObtudzPdWXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STAT1.1.4 - Correlation and Scatter Plots\n",
        "\n",
        "Next, let's explore how different numeric features in the Titanic dataset relate to one another.\n",
        "We'll calculate a correlation matrix using the Pearson correlation coefficient."
      ],
      "metadata": {
        "id": "WN6I9sF9fMpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select numeric columns to explore\n",
        "cols = [\"Survived\", \"Age\", \"SibSp\", \"Fare\", \"Parch\", \"Pclass\"]\n",
        "\n",
        "# Display the correlation matrix\n",
        "# TODO - display the correlation matrix"
      ],
      "metadata": {
        "id": "i80CU7KzjHRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ’­ Reflection: Interpreting Correlations\n",
        "\n",
        "**Fill in the following table to indicate which variables have the strongest correlation with Survival**\n",
        "\n",
        "|Variable|Direction of Correlation|Magnitude of Correlation|Interpretation|\n",
        "|:-|:-|:-|:-|\n",
        "|Age| TODO - direction | TODO - magnitude | TODO-interpretation|\n",
        "|Passenger Class| TODO - direction | TODO - magnitude | TODO-interpretation|\n",
        "|Siblings/Spouses Aboard| TODO - direction | TODO - magnitude | TODO-interpretation|\n",
        "|Parents/Children Aboard| TODO - direction | TODO - magnitude | TODO-interpretation|\n",
        "|Fare| TODO - direction | TODO - magnitude | TODO-interpretation|\n",
        "\n",
        "\n",
        "**Which variable has the strongest relationship with survival, and what might explain it?**\n",
        "\n",
        "TODO - answer\n",
        "\n",
        "**How does `Fare` relate to `Survived`, and why does this make sense historically?**\n",
        "\n",
        "TODO - answer\n",
        "\n",
        "**Why do variables like Age, SibSp, and Parch show such weak correlations with survival?**\n",
        "\n",
        "TODO - answer"
      ],
      "metadata": {
        "id": "F0eDgV8lk9tN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STAT1.2.1 - Cleaning data"
      ],
      "metadata": {
        "id": "J5yuRFE5cK6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "OqHTDiqYcQqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result shows that the following columns contain some missing values:\n",
        "\n",
        "\n",
        "*   **Age**: 177 rows missing (20% of rows)\n",
        "*   **Embarked**: 2 rows missing (0.2% of rows)\n",
        "*   **Cabin**: 687 rows missing (77% of rows)\n",
        "\n",
        "## Handling Missing Age Values\n",
        "\n",
        "For `Age`, we can assign the median age of the overall dataset to the missing.\n",
        "\n",
        "Using the median to fill in missing data is usually a safe bet for a few reasons:\n",
        "*   It is resistant to outliers.\n",
        "*   It preserves the overall shape of the age distribution.\n",
        "*   It keeps the dataset usable without biasing survival predictions too much. Dropping 20% of rows would shrink our training data and might remove meaningful patterns; filling them with the median is a low-distortion compromise.\n",
        "\n",
        "## Handling Missing Embarked Values\n",
        "The `Embarked` field contains the port that passengers embarked from. Since only 2 rows are missing this information, we could either drop them, or fill them in with the most common port. We'll do the latter.\n",
        "\n",
        "## Handling Missing Cabin Values\n",
        "The majority (77%) of these values are missing. It's best to drop this column altogether.\n",
        "\n"
      ],
      "metadata": {
        "id": "drMfhdyGdq43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing Age values with the median age\n",
        "# TODO - fill as described"
      ],
      "metadata": {
        "id": "cD6wPcgxc6Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing Embarked values with the most common port (mode)\n",
        "# TODO - fill as described"
      ],
      "metadata": {
        "id": "_BqN10q_fhs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the Cabin column since most values are missing\n",
        "# TODO - drop as described"
      ],
      "metadata": {
        "id": "xvDXyi_1f2fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-run df.info() and see that the columns have updated as we expect.\n",
        "df.info()"
      ],
      "metadata": {
        "id": "Y2S3B6Omf4Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STAT1.2.2 - Feature Engineering\n",
        "\n",
        "Use the existing `SibSp` and `Parch` columns in the dataframe to engineer a new column, or feature, called `FamilySize` that captures the total number of family members onboard for a given passenger."
      ],
      "metadata": {
        "id": "t6b8HLqPB9ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the columns `Parch` and `SibSp` and assign them to a\n",
        "# new column called `FamilySize`\n",
        "# TODO - create new column as described\n",
        "\n",
        "# Re-run df.info() to confirm the new column has been created\n",
        "df.info()"
      ],
      "metadata": {
        "id": "nBqyrhECCM1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the mean, median, mode, range, IQR,\n",
        "# and standard deviation for the new column\n",
        "\n",
        "# TODO - do as described above\n",
        "# (hint, you already did something like this earlier in the notebook!)"
      ],
      "metadata": {
        "id": "W8ffXKIoCpZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML1.1.1 - Linear Regression\n",
        "\n",
        "Train and evaluate a linear regression model that predicts a passenger's Fare depending on their Age.\n"
      ],
      "metadata": {
        "id": "IHobXCsCbZp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO: Fill out the below sections, following the steps described.\n",
        "\n",
        "# --- 1. Define features (X) and target (y) ---\n",
        "\n",
        "\n",
        "# --- 2. Split into training and testing sets (80% train, 20% test) ---\n",
        "\n",
        "\n",
        "# --- 3. Train the model ---\n",
        "\n",
        "\n",
        "# --- 4. Make predictions on test set ---\n",
        "\n",
        "\n",
        "# --- 5. Evaluate performance ---\n",
        "# Print coefficient, intercept, MSE, and Rsquared score\n",
        "\n",
        "\n",
        "# --- 6. Visualize results ---\n",
        "\n"
      ],
      "metadata": {
        "id": "hREOvqDGiUgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's add an additional independent variable / input feature: Pclass. Your code will look very similar, but will have two features in the input array rather than just one."
      ],
      "metadata": {
        "id": "kCwG2jNbsrNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO: Fill out the below sections, following the steps described.\n",
        "\n",
        "\n",
        "# --- 1. Define features (X) and target (y) ---\n",
        "\n",
        "\n",
        "# --- 2. Split into training and testing sets ---\n",
        "\n",
        "\n",
        "# --- 3. Train model ---\n",
        "\n",
        "\n",
        "# --- 4. Predict on test set ---\n",
        "\n",
        "\n",
        "# --- 5. Evaluate performance ---\n",
        "\n",
        "\n",
        "# --- 6. Visualize (optional) ---\n",
        "# Here, we'll plot how well the model predicts fares for different Ages,\n",
        "# using one color per Pclass to make the trend easier to see.\n",
        "\n"
      ],
      "metadata": {
        "id": "1-Fkir9ki6ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’­ Reflection Questions\n",
        "**Based on your findings, how would you describe the relative correlation of Age and Pclass with Fare? Does one seem to have more potential than the other to predict a given passenger's fare? Why might that be?**\n",
        "\n",
        "TODO - answer"
      ],
      "metadata": {
        "id": "_l6LTkcFtdBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ML1.2.1 - Logistic Regression\n",
        "\n",
        "In this exercise, you'll train a logistic regression model to predict whether a passenger survived the Titanic disaster.\n",
        "\n",
        "You'll go step-by-step, selecting features, training the model, and evaluating its performance.\n",
        "\n",
        "##Step 1: Select features and encode categorical data\n",
        "Logistic regression only works with numeric features.\n",
        "We'll convert Sex and Embarked into numeric form using [one-hot encoding](https://www.geeksforgeeks.org/machine-learning/ml-one-hot-encoding/)."
      ],
      "metadata": {
        "id": "S1K_-JLqVHE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# TODO: Fill out the below sections, following the steps described.\n",
        "\n",
        "# --- 1. Define features and target ---\n",
        "\n",
        "\n",
        "# --- 2. One-hot encode categorical columns ---\n",
        "\n",
        "\n",
        "# --- 3. Split into training and testing sets ---\n",
        "\n"
      ],
      "metadata": {
        "id": "9DGC84BYV9C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Train and evaluate the logistic regression model\n",
        "Train the model and view coefficients, then evaluate model performance against test data."
      ],
      "metadata": {
        "id": "Mb4lEhdxWBQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill out the below sections, following the steps described.\n",
        "\n",
        "# --- 4. Train the logistic regression model ---\n",
        "\n",
        "\n",
        "# --- 5. Make predictions on the test set ---\n",
        "\n",
        "\n",
        "# --- 6. Evaluate model performance ---\n",
        "\n",
        "\n",
        "# --- 7. Examine feature influence on survival ---\n",
        "\n",
        "\n",
        "# Optional: Visualization\n",
        "\n"
      ],
      "metadata": {
        "id": "OnRJc2fuWM8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’­ Reflection Questions\n",
        "**What percentage of passengers in the test dataset does the model correctly classify? (accuracy)**\n",
        "\n",
        "TODO - answer\n",
        "\n",
        "\n",
        "**When the model predicts survival, how frequently is it right? (precision)**\n",
        "\n",
        "TODO - answer\n",
        "\n",
        "\n",
        "**What percentage of true surviors does the model correctly catch? (recall)**\n",
        "\n",
        "TODO - answer\n",
        "\n",
        "\n",
        "**Overall, how well does the model capture the relationship between the independent variables and `Survived`? (F1)**\n",
        "\n",
        "TODO - answer\n",
        "\n"
      ],
      "metadata": {
        "id": "Rkc1TzKgu9nn"
      }
    }
  ]
}